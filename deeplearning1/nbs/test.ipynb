{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from keras.layers import Convolution2D\n",
    "from imp import reload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'my_utils' from 'my_utils.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import my_utils;reload(my_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import my_vgg16; reload(my_vgg16)\n",
    "Vgg = my_vgg16.Vgg\n",
    "vgg = my_vgg16.Vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    import vgg16; reload(vgg16)\n",
    "    from vgg16 import Vgg16\n",
    "    vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"data/dogscats/\"\n",
    "weights_path = \"data/weights\"\n",
    "sample_path = \"data/dogscats/sample/\"\n",
    "models_path = \"data/dogscats/models/\"\n",
    "\n",
    "batch_size = 64\n",
    "train_batches = vgg.get_batches(path + \"/train\", batch_size=batch_size)\n",
    "valid_batches = vgg.get_batches(path + \"/valid\", batch_size=batch_size*2)\n",
    "\n",
    "vgg.finetune(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 813s - loss: 0.1184 - acc: 0.9687 - val_loss: 0.0494 - val_acc: 0.9815\n"
     ]
    }
   ],
   "source": [
    "vgg.fit(train_batches, valid_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Â vgg.model.save_weights(\"data/weights/test_vgg_1_epoch.h5\")\n",
    "vgg.model.load_weights(\"data/weights/test_vgg_1_epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    predict_batch = vgg.get_batches(\"data/dogscats/test1/\", batch_size=5, shuffle=False)\n",
    "    ids = map(lambda t: int(t[7:-4]), predict_batch.filenames)\n",
    "    predictions = vgg.model.predict_generator(predict_batch, val_samples=predict_batch.nb_sample)\n",
    "    isdog = predictions[:,1]\n",
    "    isdog = isdog.clip(0.05, 0.95)\n",
    "    \n",
    "    create_link(ids, isdog, submission_filename=\"data/submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "## We have seen until now that we can:\n",
    "\n",
    "1) Load a pretrained model  \n",
    "2) Finetune the model removing the last layer and adding a new one with custom number of outputs  \n",
    "3) Positioned on 50% best submissions on kaggle  \n",
    "4) Model is able to overfit  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Improving the model\n",
    "\n",
    "If train the model with 2 epochs is likely that will overfit, to avoid it the creator of VGG used dropout of 0.5.\n",
    "But we can improve forcing overfitting and using modern techniques to reduce it, so looks like what we need is\n",
    "try to force the model to overfit the data and then try to content it.\n",
    "\n",
    "### So next steps\n",
    "\n",
    "1) Split model into two blocks\n",
    "    * Convolutional layers\n",
    "    * FC layers\n",
    "\n",
    "2) Ensure we can overfit FC layers\n",
    "    * Reduce weights from VGG16 mulplying by 0.5\n",
    "    * Train the model using numpy arrays\n",
    "    * Reduce overfitting on FC using data augmentation\n",
    "\n",
    "3) Batch normalization FC model\n",
    "    * FC model with batch normalization after each Dense layer\n",
    "        * Dropout of 0.6\n",
    "        * Train and overfit\n",
    "    * FC model with VGG16 BN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split trained model into conv layers and fc layers\n",
    "vgg_conv_layers, vgg_fc_layers = my_utils.split_on_last_layer(vgg.model, Convolution2D)\n",
    "from keras.models import Sequential\n",
    "conv_model = Sequential(vgg_conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creae new model with only FC layers without dropout, with weights divided by 2\n",
    "vgg_fc_weights = [layer.get_weights() for layer in vgg_fc_layers]\n",
    "fc_model = my_utils.create_fc_model(vgg_conv_layers[-1].output_shape[1:], vgg_fc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "train_batches = vgg.get_batches(path+'train', shuffle=False, batch_size=batch_size)\n",
    "valid_batches = vgg.get_batches(path+'valid', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "valid_classes = valid_batches.classes\n",
    "train_classes = train_batches.classes\n",
    "valid_labels = my_utils.onehot(valid_classes)\n",
    "train_labels = my_utils.onehot(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_features = conv_model.predict_generator(train_batches, train_batches.nb_sample)\n",
    "    valid_features = conv_model.predict_generator(valid_batches, valid_batches.nb_sample)\n",
    "\n",
    "    models_path = \"data/dogscats/models/\"\n",
    "    my_utils.save_array(models_path + 'train_convlayer_features.bc', train_features)\n",
    "    my_utils.save_array(models_path + 'valid_convlayer_features.bc', valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_path = \"data/dogscats/models/\"\n",
    "train_features = my_utils.load_array(models_path + 'train_convlayer_features.bc')\n",
    "valid_features = my_utils.load_array(models_path + 'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23000, 512, 14, 14), (2000, 512, 14, 14)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: x.shape, [train_features, valid_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/6\n",
      "18624/23000 [=======================>......] - ETA: 9s - loss: 0.0432 - acc: 0.9866"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-78f4f1ee4b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     fc_model.fit(train_features, train_labels, nb_epoch=6, \n\u001b[0;32m----> 3\u001b[0;31m              batch_size=batch_size, validation_data=(valid_features, valid_labels))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    fc_model.fit(train_features, train_labels, nb_epoch=6, \n",
    "             batch_size=batch_size, validation_data=(valid_features, valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets use data augmentatin to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augmented images generator\n",
    "from keras.preprocessing import image\n",
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = vgg.get_batches(path+'train', gen, shuffle=True, batch_size=batch_size)\n",
    "valid_batches = vgg.get_batches(path+'valid', gen, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "conv_model = Sequential(vgg_conv_layers)\n",
    "fc_model = my_utils.create_fc_model(vgg_conv_layers[-1].output_shape[1:], vgg_fc_weights)\n",
    "for layer in conv_model.layers: layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_model.add(fc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_model.compile(optimizer=my_utils.rms_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23000/23000 [==============================] - 807s - loss: 0.0553 - acc: 0.9808 - val_loss: 0.0470 - val_acc: 0.9840\n",
      "Epoch 2/2\n",
      "23000/23000 [==============================] - 809s - loss: 0.0432 - acc: 0.9853 - val_loss: 0.0431 - val_acc: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fe91d4690>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample, nb_epoch=2, \n",
    "                        validation_data=valid_batches, nb_val_samples=valid_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fully connected model with batch normalization\n",
    "\n",
    "We have seen that using data augmentation we can content overfitting a bit, but not much. Lets use more near state of the art techniques: *Batch normalization*\n",
    "\n",
    "So first of all I'm going train a FC model using batch normalization with dropout, and then join it with the convolutional layers.\n",
    "\n",
    "Batch normalization have become a standard part of the architecture of deep learning networks. As it normalizes the weights of the layer, back propagation issue is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_bn = Vgg(batch_norm=True)\n",
    "vgg_bn_conv_layers, vgg_bn_fc_layers = my_utils.split_on_last_layer(vgg_bn.model, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_bn_model = my_utils.create_fc_bn_model(input_shape=vgg_bn_conv_layers[-1].output_shape[1:], dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for from_layer, to_layer in zip(vgg_bn_fc_layers, fc_bn_model.layers):\n",
    "    to_layer.set_weights(from_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "fc_bn_model.pop()\n",
    "# for layer in fc_bn_model.layers: layer.trainable = False\n",
    "fc_bn_model.add(Dense(2, activation=\"softmax\"))\n",
    "fc_bn_model.compile(\"adam\", \"categorical_crossentropy\", [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fc_bn_model.optimizer.lr.set_value(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "23000/23000 [==============================] - 57s - loss: 0.4800 - acc: 0.9608 - val_loss: 0.3173 - val_acc: 0.9740\n",
      "Epoch 2/4\n",
      "23000/23000 [==============================] - 58s - loss: 0.1891 - acc: 0.9738 - val_loss: 0.0930 - val_acc: 0.9780\n",
      "Epoch 3/4\n",
      "23000/23000 [==============================] - 59s - loss: 0.0809 - acc: 0.9825 - val_loss: 0.0823 - val_acc: 0.9810\n",
      "Epoch 4/4\n",
      "23000/23000 [==============================] - 59s - loss: 0.0548 - acc: 0.9888 - val_loss: 0.1117 - val_acc: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f869d4bd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_bn_model.fit(train_features, train_labels, nb_epoch=4,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_data=(valid_features, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 58s - loss: 0.0249 - acc: 0.9946 - val_loss: 0.0739 - val_acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f7ee33b50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_bn_model.optimizer.lr.set_value(0.0001)\n",
    "fc_bn_model.fit(train_features, train_labels, nb_epoch=1,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_data=(valid_features, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_bn_model.save_weights(weights_path + \"/fc_bn_model_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_bn_model.load_weights(weights_path + \"/fc_bn_model_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "conv_layers, fc_layers = my_utils.split_on_last_layer(Vgg().model, Convolution2D)\n",
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: layer.trainable = False\n",
    "fc_bn_layers = my_utils.create_fc_bn_layers(input_shape=final_model.layers[-1].output_shape[1:], dropout=0.6)\n",
    "fc_bn_layers.pop()\n",
    "for layer in fc_bn_layers: layer.trainable = False\n",
    "fc_bn_layers.append(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "for layer in fc_bn_layers: final_model.add(layer)\n",
    "\n",
    "for from_layer, to_layer in zip(fc_bn_model.layers, fc_bn_layers):\n",
    "    to_layer.set_weights(from_layer.get_weights())\n",
    "\n",
    "# final_model.add(fc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_model.compile(\"adam\", \"categorical_crossentropy\", [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 767s - loss: 0.0328 - acc: 0.9943 - val_loss: 0.1204 - val_acc: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f7653bad0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_batches = vgg.get_batches(path + \"/train\", batch_size=batch_size)\n",
    "valid_batches = vgg.get_batches(path + \"/valid\", batch_size=batch_size)\n",
    "final_model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample, nb_epoch=1,\n",
    "                        validation_data=valid_batches, nb_val_samples=valid_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(weights_path + \"/final_1_dropout_08.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "(12500, 2)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    predict_batch = vgg.get_batches(\"data/dogscats/test1/\", batch_size=5, shuffle=False)\n",
    "    ids = map(lambda t: int(t[7:-4]), predict_batch.filenames)\n",
    "    predictions = final_model.predict_generator(predict_batch, val_samples=predict_batch.nb_sample)\n",
    "    isdog = predictions[:,1]\n",
    "    isdog = isdog.clip(0.05, 0.95)\n",
    "    \n",
    "    my_utils.create_link(ids, isdog, submission_filename=\"data/submission_final_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='data/submission_final_3.csv' target='_blank'>data/submission_final_3.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/courses/deeplearning1/nbs/data/submission_final_3.csv"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_utils.create_link(ids, isdog, submission_filename=\"data/submission_final_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
